FLUX TRANSFORMER: COMPLETE DATA FLOW ARCHITECTURE
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════

INPUT STAGE: MULTI-MODAL CONDITIONING & EMBEDDING
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                                                                             │
│    VISUAL INPUT PIPELINE                  TEXT INPUT PIPELINE                     TEMPORAL CONDITIONING     │
│ ┌─────────────────────┐                  ┌─────────────────────┐                ┌─────────────────────┐     │
│ │ RGB Image           │                  │ Text Prompt         │                │ Timestep t ∈ [0,1]  │     │
│ │ [B, 3, H, W]        │                  │ "A beautiful beach" │                │ Guidance strength   │     │
│ │e.g., [1,3,1024,1024]│                 │ List[str]           │                │ [B] tensors         │     │
│ └─────────────────────┘                  └─────────────────────┘                └─────────────────────      │
│         │                                          │                                     │                  │
│         ▼                                          ▼                                     ▼                  │
│ ┌─────────────────────┐                  ┌─────────────────────┐                ┌─────────────────────┐     │
│ │ VAE Encoder         │                  │ DUAL TEXT ENCODERS  │                │ Sinusoidal Embedding│     │
│ │ autoencoder.py:309  │                  │ conditioner.py      │                │ timestep_embedding()│     │
│ │ Conv2d layers       │                  │ ┌─────────────────┐ │                │ layers.py:28-49     │     │
│ │ ResNet + Attention  │                  │ │ T5 Encoder      │ │                │ ┌─────────────────┐ │     │
│ │ 3 → 16 channels     │                  │ │ Sequential emb  │ │                │ │ freqs = exp(-log│ │     │
│ │ H,W → H/8, W/8      │                  │ │ max_len=512     │ │                │ │ (10000)*range/  │ │     │
│ └─────────────────────┘                  │ │ [B,512,4096]    │ │                │ │ half) * 1000    │ │     │
│         │                                │ └─────────────────┘ │                │ │ cos/sin args    │ │     │
│         ▼                                │ ┌─────────────────┐ │                │ └─────────────────┘ │     │
│ ┌─────────────────────┐                  │ │ CLIP Encoder    │ │                │ [B, 256]            │     │
│ │ VAE Latent Space    │                  │ │ Pooled vector   │ │                └─────────────────────┘     │
│ │ [B, 16, H/8, W/8]   │                  │ │ max_len varies  │ │                         │                  │
│ │ e.g.,[1,16,128,128] │                  │ │ [B, 768]        │ │                         ▼                  │
│ └─────────────────────┘                  │ └─────────────────┘ │                ┌─────────────────────┐     │
│         │                                └─────────────────────┘                │ MLPEmbedder         │     │
│         ▼                                          │                            │ time_in: 256→hidden │     │
│ ┌─────────────────────┐                            ▼                            │ Linear→SiLU→Linear  │     │
│ │ Patch Embedding     │                  ┌─────────────────────┐                │ model.py:61         │     │
│ │ sampling.py:41      │                  │ Text Conditioning   │                └─────────────────────┘     │
│ │ rearrange operation │                  │ Split Processing    │                         │                  │
│ │ "b c (h ph) (w pw)  │                  │ ┌─────────────────┐ │                         ▼                  │
│ │ -> b (h w)(c ph pw)"│                  │ │ T5 → txt_in     │ │                ┌─────────────────────┐     │
│ │ ph=2, pw=2          │                  │ │ Linear(4096,    │ │                │ Guidance Embedding  │     │
│ │ 16×4 = 64 chan      │                  │ │       hidden)   │ │                │ guidance_in  if used│     │
│ └─────────────────────┘                  │ │ model.py:66     │ │                │ 256→hidden_size     │     │
│         │                                │ └─────────────────┘ │                │ model.py:63-65      │     │
│         ▼                                │ ┌─────────────────┐ │                └─────────────────────┘     │
│ ┌─────────────────────┐                  │ │ CLIP → vec_in   │ │                         │                  │
│ │ Spatial Indexing    │                  │ │ MLPEmbedder     │ │                         ▼                  │
│ │ sampling.py:45-48   │                  │ │ (768, hidden)   │ │                ┌─────────────────────┐     │
│ │ img_ids creation    │                  │ │ model.py:64     │ │                │ Vector Combination   │    │
│ │ [h//2, w//2, 3]     │                  │ └─────────────────┘ │                │ vec = time_emb +     │    │
│ │ (...,1)=h, (...,2)=w│                  └─────────────────────┘                │       guidance_emb + │    │
│ │ [B, H×W/4, 3]       │                            │                            │       vector_in(clip)│    │
│ └─────────────────────┘                            ▼                            │ [B, hidden_size]     │    │
│         │                                ┌─────────────────────┐                └─────────────────────┘     │
│         ▼                                │ Text Token Sequence │                         │                  │
│ ┌─────────────────────┐                  │ [B, 512, hidden]    │                         │                  │
│ │ Visual Embedding    │                  │ txt_ids=[B,512,3]   │                         │                  │
│ │ img_in = Linear     │                  └─────────────────────┘                         │                  │
│ │ (64, hidden_size)   │                            │                                     │                  │
│ │ model.py:60         │                            │                                     │                  │
│ │ bias=True           │                            │                                     │                  │
│ └─────────────────────┘                            │                                     │                  │
│         │                                          │                                     │                  │
│         ▼                                          │                                     │                  │
│ ┌─────────────────────┐                            │                                     │                  │
│ │ Visual Token Seq    │                            │                                     │                  │
│ │ [B, H×W/4, hidden]  │                            │                                     │                  │
│ │ img_ids=[B,H×W/4,3] │                            │                                     │                  │
│ └─────────────────────┘                            │                                     │                  │
│         │                                          │                                     │                  │
│         └────────────────┬─────────────────────────┘                                     │                  │
│                          ▼                                                               │                  │
│                ┌─────────────────────┐                                                   │                  │
│                │ ID Concatenation    │ ←─────────────────────────────────────────────────┘                  │
│                │ ids = torch.cat(    │                                                                      │
│                │   (txt_ids,img_ids),│                                                                      │
│                │   dim=1)            │                                                                      │
│                │ [B,512+H×W/4,3]     │                                                                      │
│                │ model.py:107        │                                                                      │
│                └─────────────────────┘                                                                      │
│                          │                                                                                  │
│                          ▼                                                                                  │
│                ┌─────────────────────┐                                                                      │
│                │ Positional Encoding │                                                                      │
│                │ pe_embedder(ids)    │                                                                      │
│                │ EmbedND: RoPE       │                                                                      │
│                │ Rotary 2D spatial   │                                                                      │
│                │ pe: [B,1,seq,head]  │                                                                      │
│                │ model.py:108        │                                                                      │
│                └─────────────────────┘                                                                      │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

DUAL-STREAM PROCESSING: 19 × DoubleStreamBlock
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ for block in self.double_blocks:  # model.py:110                                                            │
│     img, txt = block(img=img, txt=txt, vec=vec, pe=pe)                                                      │
│                                                                                                             │
│    EACH DoubleStreamBlock (layers.py:129-191):                                                              │
│                                                                                                             │
│ ┌─────────────────────┐                          ┌─────────────────────┐                                    │
│ │ IMG STREAM          │                          │ TXT STREAM          │                                    │
│ │ [B, H×W/4, hidden]  │                          │ [B, 512, hidden]    │                                    │
│ └─────────────────────┘                          └─────────────────────┘                                    │
│         │                                                  │                                                │
│         ▼                                                  ▼                                                │
│ ┌─────────────────────┐    ┌─────────────────────┐    ┌─────────────────────┐                               │
│ │ Vector Modulation   │    │ Vector Conditioning │    │ Vector Modulation   │                               │
│ │ img_mod1, img_mod2  │    │ vec: [B, hidden]    │    │ txt_mod1, txt_mod2  │                               │
│ │ = img_mod(vec)      │    │ Combined time+guid+ │    │ = txt_mod(vec)      │                               │
│ │ Returns:            │    │ CLIP pooled vectors │    │ Returns:            │                               │
│ │ • shift, scale, gate│ ←──┤ Broadcast to all    │──→ │ • shift, scale, gate│                               │
│ │ • For attn & mlp    │    │ components          │    │ • For attn & mlp    │                               │
│ └─────────────────────┘    └─────────────────────┘    └─────────────────────┘                               │
│         │                                                  │                                                │
│         ▼                                                  ▼                                                │
│ ┌─────────────────────┐                          ┌─────────────────────┐                                    │
│ │ Adaptive LayerNorm  │                          │ Adaptive LayerNorm  │                                    │
│ │ img_norm = LayerNorm│                          │ txt_norm = LayerNorm│                                    │
│ │ (elementwise_affine │                          │ (elementwise_affine │                                    │
│ │  =False)            │                          │  =False)            │                                    │
│ │ img_mod = (1+scale) │                          │ txt_mod = (1+scale) │                                    │
│ │ * norm(img) + shift │                          │ * norm(txt) + shift │                                    │
│ └─────────────────────┘                          └─────────────────────┘                                    │
│         │                                                  │                                                │
│         ▼                                                  ▼                                                │
│ ┌─────────────────────┐                          ┌─────────────────────┐                                    │
│ │ QKV Computation     │                          │ QKV Computation     │                                    │
│ │ qkv = Linear        │                          │ qkv = Linear        │                                    │
│ │ (hidden, 3*hidden,  │                          │ (hidden, 3*hidden,  │                                    │
│ │  bias=qkv_bias)     │                          │  bias=qkv_bias)     │                                    │
│ │ img_q,img_k,img_v = │                          │ txt_q,txt_k,txt_v = │                                    │
│ │ rearrange(qkv,      │                          │ rearrange(qkv,      │                                    │
│ │ "B L (K H D)->      │                          │ "B L (K H D)->      │                                    │
│ │  K B H L D", K=3)   │                          │  K B H L D", K=3)   │                                    │
│ └─────────────────────┘                          └─────────────────────┘                                    │
│         │                                                  │                                                │
│         ▼                                                  ▼                                                │
│ ┌─────────────────────┐                          ┌─────────────────────┐                                    │
│ │ QK Normalization    │                          │ QK Normalization    │                                    │
│ │ img_q,img_k=norm(q,k│                          │ txt_q,txt_k=norm(q,k│                                    │
│ │ RMSNorm per head    │                          │ RMSNorm per head    │                                    │
│ │ Stabilizes training │                          │ Stabilizes training │                                    │
│ └─────────────────────┘                          └─────────────────────┘                                    │
│         │                                                  │                                                │
│         └────────────────┬─────────────────────────────────┘                                                │
│                          ▼                                                                                  │
│                ┌─────────────────────┐                                                                      │
│                │  CROSS-MODAL        │                                                                      │
│                │ ATTENTION           │                                                                      │
│                │ q = cat(txt_q,img_q)│ ← KEY INNOVATION: Joint attention!                                   │
│                │ k = cat(txt_k,img_k)│                                                                      │
│                │ v = cat(txt_v,img_v)│                                                                      │
│                │ attn = attention(   │                                                                      │
│                │   q,k,v,pe=pe)      │                                                                      │
│                │ [B,H,txt+img,D]     │                                                                      │
│                └─────────────────────┘                                                                      │
│                          │                                                                                  │
│                          ▼                                                                                  │
│                ┌─────────────────────┐                                                                      │
│                │ ATTENTION SPLIT     │                                                                      │
│                │ txt_attn, img_attn  │                                                                      │
│                │ = attn.split(       │                                                                      │
│                │   [txt.shape[1],    │                                                                      │
│                │    img.shape[1]])   │                                                                      │
│                └─────────────────────┘                                                                      │
│         ┌────────────────┴─────────────────┐                                                                │
│         ▼                                  ▼                                                                │
│ ┌─────────────────────┐          ┌─────────────────────┐                                                    │
│ │ IMG RESIDUAL CONN   │          │ TXT RESIDUAL CONN   │                                                    │
│ │ img = img +         │          │ txt = txt +         │                                                    │
│ │   img_mod1.gate *   │          │   txt_mod1.gate *   │                                                    │
│ │   proj(img_attn)    │          │   proj(txt_attn)    │                                                    │
│ └─────────────────────┘          └─────────────────────┘                                                    │
│         │                                  │                                                                │
│         ▼                                  ▼                                                                │
│ ┌─────────────────────┐          ┌─────────────────────┐                                                    │
│ │ IMG MLP BLOCK       │          │ TXT MLP BLOCK       │                                                    │
│ │ mlp_input = (1+     │          │ mlp_input = (1+     │                                                    │
│ │   img_mod2.scale) * │          │   txt_mod2.scale) * │                                                    │
│ │   norm2(img) +      │          │   norm2(txt) +      │                                                    │
│ │   img_mod2.shift    │          │   txt_mod2.shift    │                                                    │
│ │ mlp = Linear→GELU→  │          │ mlp = Linear→GELU→  │                                                    │
│ │       Linear        │          │       Linear        │                                                    │
│ │ img = img +         │          │ txt = txt +         │                                                    │
│ │   img_mod2.gate *   │          │   txt_mod2.gate *   │                                                    │
│ │   mlp(mlp_input)    │          │   mlp(mlp_input)    │                                                    │
│ └─────────────────────┘          └─────────────────────┘                                                    │
│         │                                  │                                                                │
│         └────────────────┬─────────────────┘                                                                │
│                          ▼                                                                                  │
│                    (img, txt) output                                                                        │
│                                                                                                             │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

STREAM FUSION: Concatenation Strategy
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ # CRITICAL OPERATION: model.py:113                                                                          │
│ img = torch.cat((txt, img), 1)                                                                              │
│                                                                                                             │
│  TENSOR SHAPES:                                                                                             │
│ • txt: [B, 512, hidden_size]        ← Text tokens (always first!)                                           │
│ • img: [B, H×W/4, hidden_size]      ← Visual tokens (appended)                                              │
│ • Result: [B, 512 + H×W/4, hidden_size] ← Unified sequence                                                  │
│                                                                                                             │
│  MEMORY LAYOUT:                                                                                             │
│ ┌─────────────────────────────────────────────────────────────────────────────────────────────────────────┐ │
│ │ Index:  0    1    2  ...  511  512  513  514  ...  511+H×W/4                                            │ │
│ │ Content:[txt][txt][txt]...[txt][img][img][img]...[img]                                                  │ │
│ │ Type:   TEXT_TOKEN_SEQUENCE    |   VISUAL_TOKEN_SEQUENCE                                                │ │
│ └─────────────────────────────────────────────────────────────────────────────────────────────────────────┘ │
│ • Visual tokens start at index txt.shape[1] = 512                                                           │
│ • To extract visual: img_tokens = x[:, 512:, :]                                                             │
│ • To extract text: txt_tokens = x[:, :512, :]                                                               │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

SINGLE-STREAM PROCESSING: 38 × SingleStreamBlock  
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ for block in self.single_blocks:  # model.py:114-115                                                        │
│     img = block(img, vec=vec, pe=pe)                                                                        │
│                                                                                                             │
│    EACH SingleStreamBlock (layers.py:194-239): PARALLEL ARCHITECTURE                                        │
│                                                                                                             │
│ ┌─────────────────────┐                                                                                     │
│ │ UNIFIED SEQUENCE    │ ← Input: [B, 512 + H×W/4, hidden_size]                                              │
│ │ [txt_tokens |       │   Contains both text and visual tokens                                              │
│ │  img_tokens]        │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ Vector Modulation   │                                                                                     │
│ │ mod, _ = modulation │                                                                                     │
│ │ (vec)               │                                                                                     │
│ │ Returns single      │                                                                                     │
│ │ ModulationOut:      │                                                                                     │
│ │ • shift, scale, gate│                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ Pre-Normalization   │                                                                                     │
│ │ x_mod = (1 +        │                                                                                     │
│ │   mod.scale) *      │                                                                                     │
│ │   pre_norm(x) +     │                                                                                     │
│ │   mod.shift         │                                                                                     │
│ │ LayerNorm applied   │                                                                                     │
│ │ to full sequence    │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │  PARALLEL SPLIT     │ ← KEY EFFICIENCY INNOVATION!                                                        │
│ │ qkv, mlp = split(   │                                                                                     │
│ │   linear1(x_mod),   │                                                                                     │
│ │   [3*hidden_size,   │                                                                                     │
│ │    mlp_hidden_dim], │                                                                                     │
│ │   dim=-1)           │                                                                                     │
│ │                     │                                                                                     │
│ │ linear1 projects to │                                                                                     │
│ │ 3*hidden + mlp_dim  │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│    ┌────┴─────┐                                                                                             │
│    ▼          ▼                                                                                             │
│ ┌─────────────────────┐               ┌─────────────────────┐                                               │
│ │ ATTENTION PATH      │               │ MLP PATH            │                                               │
│ │ q,k,v = rearrange( │                │ mlp_out = mlp_act(  │                                               │
│ │   qkv, "B L (K H D) │               │   mlp)              │                                               │
│ │   -> K B H L D",    │               │ GELU activation     │                                               │
│ │   K=3, H=num_heads) │               │ [B, seq_len,        │                                               │
│ │                     │               │  mlp_hidden_dim]    │                                               │
│ │ q,k = norm(q,k,v)   │ ← QK RMSNorm  │                     │                                               │
│ │ QKNorm per head     │               │                     │                                               │
│ │                     │               │                     │                                               │
│ │ attn = attention(   │               │                     │                                               │
│ │   q, k, v, pe=pe)   │               │                     │                                               │
│ │ Full self-attention │               │                     │                                               │
│ │ on unified sequence │               │                     │                                               │
│ │ [B, seq_len, hidden]│               │                     │                                               │
│ └─────────────────────┘               └─────────────────────┘                                               │
│         │                                       │                                                           │
│         └─────────────┬─────────────────────────┘                                                           │
│                       ▼                                                                                     │
│ ┌─────────────────────┐                                                                                     │
│ │ PARALLEL COMBINE    │                                                                                     │
│ │ output = linear2(   │                                                                                     │
│ │   torch.cat((attn,  │                                                                                     │
│ │             mlp_out)│                                                                                     │
│ │            , dim=2))│                                                                                     │
│ │ Projects back to    │                                                                                     │
│ │ hidden_size         │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ RESIDUAL CONNECTION │                                                                                     │
│ │ return x + mod.gate │                                                                                     │
│ │        * output     │                                                                                     │
│ │ Gated residual with │                                                                                     │
│ │ conditioning        │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│    Next block input                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

VISUAL TOKEN EXTRACTION & OUTPUT STAGE
┌─────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ # Extract only visual tokens: model.py:116                                                                  │
│ img = img[:, txt.shape[1]:, ...]                                                                            │
│                                                                                                             │
│    EXTRACTION PROCESS:                                                                                      │
│ • Input: [B, 512 + H×W/4, hidden_size] ← Unified sequence                                                   │
│ • txt.shape[1] = 512 ← Text sequence length                                                                 │
│ • Output: [B, H×W/4, hidden_size] ← Pure visual tokens                                                      │
│                                                                                                             │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ FINAL LAYER         │                                                                                     │
│ │ LastLayer           │                                                                                     │
│ │ layers.py:242-253   │                                                                                     │
│ │ ┌─────────────────┐ │                                                                                     │
│ │ │ AdaLN Modulation│ │ ← Final conditioning with vector                                                    │
│ │ │ shift, scale =  │ │                                                                                     │
│ │ │ adaLN_mod(vec)  │ │                                                                                     │
│ │ │ .chunk(2, dim=1)│ │                                                                                     │
│ │ └─────────────────┘ │                                                                                     │
│ │ ┌─────────────────┐ │                                                                                     │
│ │ │ Final LayerNorm │ │                                                                                     │
│ │ │ x = (1 + scale  │ │                                                                                     │
│ │ │   [:, None, :]) │ │                                                                                     │
│ │ │   * norm_final  │ │                                                                                     │
│ │ │   (x) + shift   │ │                                                                                     │
│ │ │   [:, None, :]  │ │                                                                                     │
│ │ └─────────────────┘ │                                                                                     │
│ │ ┌─────────────────┐ │                                                                                     │
│ │ │ Linear Project  │ │                                                                                     │
│ │ │ x = linear(x)   │ │                                                                                     │
│ │ │ hidden_size →   │ │                                                                                     │
│ │ │ patch_size² *   │ │                                                                                     │
│ │ │ out_channels    │ │                                                                                     │
│ │ │ = 1² * 16 = 16  │ │                                                                                     │
│ │ └─────────────────┘ │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ VELOCITY FIELD      │ ← This is the MODEL OUTPUT for flow matching!                                       │
│ │ [B, H×W/4, 16]      │   NOT noise like traditional diffusion                                              │
│ │ Flow prediction     │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ DENOISE INTEGRATION │ ← Used in sampling loop                                                             │
│ │ sampling.py:266-267 │                                                                                     │
│ │ img = img + (t_prev │                                                                                     │
│ │   - t_curr) * pred  │   Euler method integration                                                          │
│ │ Rectified flow      │                                                                                     │
│ │ straight-line path  │                                                                                     │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼ (After sampling loop completes)                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ SPATIAL UNPACKING   │                                                                                     │
│ │ sampling.py:274-282 │                                                                                     │
│ │ unpack(x, h, w):    │                                                                                     │
│ │ rearrange(x,        │                                                                                     │
│ │ "b (h w)(c ph pw) → │                                                                                     │
│ │  b c (h ph)(w pw)", │                                                                                     │
│ │ h=ceil(height/16),  │                                                                                     │
│ │ w=ceil(width/16),   │                                                                                     │
│ │ ph=2, pw=2)         │                                                                                     │
│ │ Result: [B,16,H/8,W/8]                                                                                    │
│ └─────────────────────┘                                                                                     │
│         │                                                                                                   │
│         ▼                                                                                                   │
│ ┌─────────────────────┐                                                                                     │
│ │ VAE DECODING        │                                                                                     │
│ │ autoencoder.py:352  │                                                                                     │
│ │ z = z / scale_factor│                                                                                     │
│ │     + shift_factor  │                                                                                     │
│ │ decoder(z)          │                                                                                     │
│ │ 16 channels →       │                                                                                     │
│ │ 3 RGB channels      │                                                                                     │
│ │ H/8,W/8 → H,W       │                                                                                     │
│ │ Final:[B,3,H,W]     │                                                                                     │
│ └─────────────────────┘                                                                                     │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
